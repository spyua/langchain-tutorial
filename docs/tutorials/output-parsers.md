# LangChain Output Parsers æ•™å­¸ï¼šè®“ LLM è¼¸å‡ºè‡ªå‹•çµæ§‹åŒ–

åœ¨ä½¿ç”¨å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼Œä¾‹å¦‚ GPTã€Claudeã€Geminiï¼‰æ™‚ï¼Œæˆ‘å€‘ç¶“å¸¸é‡åˆ°ä¸€å€‹å•é¡Œï¼š
ğŸ‘‰ æ¨¡å‹è¼¸å‡ºçš„çµæœæ˜¯ã€Œç´”æ–‡å­—ã€ï¼Œä½†æˆ‘å€‘å¯¦éš›éœ€è¦çš„æ˜¯ **çµæ§‹åŒ–è³‡æ–™**ï¼ˆJSONã€æ¸…å–®ã€æ™‚é–“æ ¼å¼â€¦â€¦ï¼‰ã€‚

åœ¨å‚³çµ±æ–¹å¼ä¸‹ï¼Œæˆ‘å€‘å¯èƒ½æœƒä½¿ç”¨ **æ­£å‰‡è¡¨é”å¼ï¼ˆregexï¼‰** ä¾†è§£æï¼Œä½†é€™ä¸åƒ…ç¹ç‘£ï¼Œä¹Ÿå®¹æ˜“å‡ºéŒ¯ã€‚
ç‚ºäº†è§£æ±ºé€™å€‹å•é¡Œï¼Œ**LangChain æä¾›äº†å¤šç¨®çµæ§‹åŒ–è¼¸å‡ºæ–¹æ¡ˆ**ï¼Œå¹«åŠ©æˆ‘å€‘æŠŠ LLM çš„è¼¸å‡ºè‡ªå‹•è½‰æ›æˆçµæ§‹åŒ–è³‡æ–™ã€‚

---

## å…©åˆ†é˜æ‡‚ï¼šç‚ºä½•è¦çµæ§‹åŒ–è¼¸å‡ºï¼Ÿ

LLM çš„åŸå§‹è¼¸å‡ºé€šå¸¸æ˜¯éçµæ§‹åŒ–çš„æ–‡å­—ï¼Œä½†å¯¦éš›æ‡‰ç”¨ä¸­æˆ‘å€‘ç¶“å¸¸éœ€è¦çµæ§‹åŒ–è³‡æ–™ä¾†é€²è¡Œå¾ŒçºŒè™•ç†ã€‚

### âŒ å•é¡Œå ´æ™¯ï¼šè™•ç†ç´”æ–‡å­—è¼¸å‡º

```python
# å‚³çµ±æ–¹å¼ï¼šLLM è¼¸å‡ºç´”æ–‡å­—ï¼Œéœ€è¦æ‰‹å‹•è§£æ
from langchain_openai import ChatOpenAI  # âœ… v0.3 æ­£ç¢ºåŒ¯å…¥è·¯å¾‘

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
response = llm.invoke("åˆ†æé€™ç¯‡æ–‡ç« çš„æƒ…æ„Ÿï¼Œä¸¦çµ¦å‡º 0-10 åˆ†çš„ä¿¡å¿ƒæŒ‡æ•¸")

print(response.content)  
# è¼¸å‡ºï¼š"é€™ç¯‡æ–‡ç« æ•´é«”æƒ…æ„Ÿåå‘æ­£é¢ï¼Œä¿¡å¿ƒæŒ‡æ•¸ç´„ 85%ï¼Œä¸»è¦æƒ…æ„Ÿé¡åˆ¥æ˜¯æ¨‚è§€..."

# ğŸ˜¤ éœ€è¦æ‰‹å‹•è§£æå­—ä¸²ï¼Œå®¹æ˜“å‡ºéŒ¯ä¸”ä¸å¯é 
if "æ­£é¢" in response.content:
    sentiment = "positive"
else:
    sentiment = "negative"
# é€™ç¨®æ–¹å¼éå¸¸è„†å¼±ï¼
```

### âœ… è§£æ±ºæ–¹æ¡ˆï¼šçµæ§‹åŒ–è¼¸å‡º

```python
from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# å®šç¾©çµæ§‹åŒ–è¼¸å‡ºæ ¼å¼
class SentimentAnalysis(BaseModel):
    sentiment: str = Field(description="æƒ…æ„Ÿå‚¾å‘ï¼špositive, negative, neutral")
    confidence: float = Field(description="ä¿¡å¿ƒæŒ‡æ•¸ 0-1", ge=0, le=1)
    emotions: list[str] = Field(description="æª¢æ¸¬åˆ°çš„æƒ…æ„Ÿæ¸…å–®")
    summary: str = Field(description="åˆ†æç¸½çµ")

# ä½¿ç”¨ with_structured_outputï¼ˆæœ€æ¨è–¦ï¼ï¼‰
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
structured_llm = llm.with_structured_output(SentimentAnalysis)

prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å°ˆæ¥­çš„æƒ…æ„Ÿåˆ†æå¸«"),
    ("human", "åˆ†æä»¥ä¸‹æ–‡å­—çš„æƒ…æ„Ÿï¼š{text}")
])

chain = prompt | structured_llm
result = chain.invoke({"text": "ä»Šå¤©å¤©æ°£çœŸå¥½ï¼"})

# å–å¾—çµæ§‹åŒ–çµæœ
print(result.sentiment)     # "positive"
print(result.confidence)    # 0.95
print(result.emotions)      # ["happiness", "optimism"]
print(type(result))         # <class 'SentimentAnalysis'>
```

---

## ğŸ† é¦–é¸æ–¹æ¡ˆï¼š`with_structured_output`

**åœ¨æ”¯æ´ JSON æ¨¡å¼çš„æ¨¡å‹ä¸Šï¼ˆOpenAIã€Anthropicã€Googleï¼‰ï¼Œé€™æ˜¯æœ€ç©©å®šä¸”æˆåŠŸç‡æœ€é«˜çš„æ–¹æ³•ã€‚**

### ç‚ºä»€éº¼æ¨è–¦ `with_structured_output`ï¼Ÿ

1. **è‡ªå‹•ç¶å®š Schema**ï¼šç„¡éœ€æ‰‹å‹•æ’°å¯«æ ¼å¼æŒ‡ç¤º
2. **å…§å»ºè§£æ**ï¼šç„¡éœ€é¡å¤–çš„è§£æå™¨
3. **é«˜æˆåŠŸç‡**ï¼šæ¨¡å‹åŸç”Ÿæ”¯æ´ï¼Œç©©å®šæ€§æ›´ä½³
4. **ç¨‹å¼ç¢¼æœ€ç°¡æ½”**ï¼šä¸€è¡Œç¶å®šå³å¯

### å®Œæ•´ç¯„ä¾‹ï¼šå•†æ¥­åç¨±ç”Ÿæˆç³»çµ±

```python
# åŒ¯å…¥å¿…è¦æ¨¡çµ„ï¼ˆv0.3 æ¨™æº–è·¯å¾‘ï¼‰
from pydantic import BaseModel, Field, field_validator
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# å®šç¾©å–®å€‹å•†æ¥­åç¨±çš„è³‡æ–™çµæ§‹
class BusinessName(BaseModel):
    """å–®å€‹å•†æ¥­åç¨±çš„å®Œæ•´è³‡è¨Š"""
    name: str = Field(description="å…¬å¸åç¨±")
    rating: float = Field(ge=0, le=10, description="è©•åˆ† (0 æœ€å·®, 10 æœ€ä½³)")
    reason: str = Field(description="è©•åˆ†ç†ç”±")

# å®šç¾©åŒ…å«å¤šå€‹å•†æ¥­åç¨±çš„å®¹å™¨çµæ§‹
class BusinessNames(BaseModel):
    """å•†æ¥­åç¨±ç”Ÿæˆçµæœçš„å®¹å™¨"""
    names: list[BusinessName] = Field(description="å•†æ¥­åç¨±æ¸…å–®")
    industry_analysis: str = Field(description="ç”¢æ¥­åˆ†æç¸½çµ")

# å»ºç«‹èŠå¤©æç¤ºæ¨¡æ¿
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯è³‡æ·±å“ç‰Œé¡§å•ï¼Œç²¾é€šå•†æ¥­å‘½åã€‚å›è¦†è«‹å®Œå…¨ç¬¦åˆæŒ‡å®šçš„çµæ§‹ã€‚"),
    ("human", "è«‹ç‚º {industry} ç”¢æ¥­ç”¢ç”Ÿ 5 å€‹å‰µæ–°çš„å…¬å¸åç¨±ï¼Œä¸¦ç‚ºæ¯å€‹åç¨±è©•åˆ†å’Œèªªæ˜ç†ç”±ã€‚")
])

# åˆå§‹åŒ–èªè¨€æ¨¡å‹ä¸¦ç¶å®šçµæ§‹åŒ–è¼¸å‡º
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
structured_llm = llm.with_structured_output(BusinessNames)

# å»ºç«‹å®Œæ•´è™•ç†éˆï¼ˆç„¡éœ€æ‰‹å‹•è§£æå™¨ï¼ï¼‰
chain = prompt | structured_llm

# åŸ·è¡Œå•†æ¥­åç¨±ç”Ÿæˆ
try:
    result = chain.invoke({"industry": "äººå·¥æ™ºæ…§"})
    
    print(f"ç”¢æ¥­åˆ†æï¼š{result.industry_analysis}")
    print("\nç”Ÿæˆçš„å•†æ¥­åç¨±ï¼š")
    
    for i, business in enumerate(result.names, 1):
        print(f"{i}. {business.name}")
        print(f"   è©•åˆ†: {business.rating}/10")
        print(f"   ç†ç”±: {business.reason}")
        print()
        
except Exception as e:
    print(f"âŒ è™•ç†å¤±æ•—: {e}")
```

### ç¯„ä¾‹è¼¸å‡º
```python
# è‡ªå‹•è§£æç‚ºçµæ§‹åŒ–ç‰©ä»¶
BusinessNames(
    names=[
        BusinessName(name='NeuralSync', rating=9.2, reason='çµåˆç¥ç¶“ç¶²è·¯æ¦‚å¿µï¼Œæ˜“è¨˜ä¸”å°ˆæ¥­'),
        BusinessName(name='CogniFlow', rating=8.8, reason='èªçŸ¥æµå‹•çš„æ¦‚å¿µï¼Œé©åˆAIæœå‹™'),
        BusinessName(name='MindForge', rating=8.5, reason='å¿ƒæ™ºé›é€ ï¼Œæš—ç¤ºAIå‰µé€ åŠ›'),
        BusinessName(name='ThinkWave', rating=8.3, reason='æ€ç¶­æ³¢å‹•ï¼Œç¾ä»£æ„Ÿå¼·'),
        BusinessName(name='LogiCore', rating=9.0, reason='é‚è¼¯æ ¸å¿ƒï¼Œçªå‡ºAIæœ¬è³ª')
    ],
    industry_analysis="äººå·¥æ™ºæ…§ç”¢æ¥­æ³¨é‡å‰µæ–°ã€æŠ€è¡“æ·±åº¦å’Œä¿¡ä»»æ„Ÿ..."
)
```

---

## å‚³çµ±æ–¹æ¡ˆï¼šOutput Parsers

ç•¶æ¨¡å‹ä¸æ”¯æ´ `with_structured_output` æˆ–éœ€è¦æ›´ç´°ç·»æ§åˆ¶æ™‚ï¼Œå¯ä»¥ä½¿ç”¨å‚³çµ±çš„ Output Parsersã€‚

### å¸¸è¦‹ Output Parser é¡å‹

| è§£æå™¨é¡å‹ | ç”¨é€” | é©ç”¨å ´æ™¯ |
|------------|------|----------|
| **`PydanticOutputParser`** | é©—è­‰/è½‰å‹æˆ Pydantic æ¨¡å‹ | è¤‡é›œæ¥­å‹™é‚è¼¯ã€é¡å‹å®‰å…¨ |
| **`JsonOutputParser`** | æŠŠè¼¸å‡ºè½‰æˆ `dict` | ç°¡å–® JSON è¼¸å‡º |
| **`CommaSeparatedListOutputParser`** | æŠŠè¼¸å‡ºåˆ‡æˆé€—è™Ÿæ¸…å–® | ç°¡å–®æ¸…å–®éœ€æ±‚ |
| **`StructuredOutputParser`** | ä»¥ `ResponseSchema` å®šç¾©æ¬„ä½ | å›ºå®šæ¬„ä½çµæ§‹ |
| **`EnumOutputParser`** | é™åˆ¶è¼¸å‡ºç‚ºæŒ‡å®šåˆ—èˆ‰ | é¸é …é™åˆ¶å ´æ™¯ |
| **`DatetimeOutputParser`** | è§£ææ—¥æœŸæ™‚é–“ | æ™‚é–“æ ¼å¼è™•ç† |
| **`XMLOutputParser`** | è§£æ XML æ ¼å¼ | XML çµæ§‹éœ€æ±‚ |

### 1. PydanticOutputParserï¼ˆæ¨è–¦ï¼‰

```python
# åŒ¯å…¥æ¨™æº–è·¯å¾‘ï¼ˆv0.3ï¼‰
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel, Field, field_validator
from langchain_openai import ChatOpenAI

# å®šç¾©ä»»å‹™æå–çš„è³‡æ–™çµæ§‹æ¨¡å‹
class TaskExtraction(BaseModel):
    """å¾æ–‡æœ¬ä¸­æå–ä»»å‹™è³‡è¨Šçš„è³‡æ–™çµæ§‹"""
    tasks: list[str] = Field(description="æå–çš„ä»»å‹™æ¸…å–®")
    priority: str = Field(description="å„ªå…ˆç´šï¼šhigh, medium, low")
    deadline: str | None = Field(default=None, description="æˆªæ­¢æ™‚é–“ï¼Œæ ¼å¼ï¼šYYYY-MM-DD")
    estimated_hours: float = Field(ge=0, description="é ä¼°å·¥æ™‚")
    
    # ä½¿ç”¨ v2 èªæ³•çš„æ¬„ä½é©—è­‰å™¨
    @field_validator('priority')
    @classmethod
    def validate_priority(cls, v: str) -> str:
        """é©—è­‰å„ªå…ˆç´šæ¬„ä½æ˜¯å¦ç‚ºæœ‰æ•ˆå€¼"""
        if v not in ['high', 'medium', 'low']:
            raise ValueError('å„ªå…ˆç´šå¿…é ˆæ˜¯ high, medium, low å…¶ä¸­ä¹‹ä¸€')
        return v

# å»ºç«‹ Pydantic è¼¸å‡ºè§£æå™¨
parser = PydanticOutputParser(pydantic_object=TaskExtraction)

# å»ºç«‹åŒ…å«æ ¼å¼æŒ‡ç¤ºçš„æç¤ºè©æ¨¡æ¿
prompt = PromptTemplate(
    template="å¾ä»¥ä¸‹æ–‡æœ¬æå–ä»»å‹™è³‡è¨Šï¼š{text}\n{format_instructions}",
    input_variables=["text"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)

# å»ºç«‹è™•ç†éˆ
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
chain = prompt | llm | parser

# åŸ·è¡Œä»»å‹™æå–
result = chain.invoke({"text": "éœ€è¦åœ¨æœ¬é€±äº”å‰å®Œæˆç¶²ç«™è¨­è¨ˆï¼Œé ä¼°éœ€è¦ 8 å°æ™‚ï¼Œé€™æ˜¯é«˜å„ªå…ˆç´šä»»å‹™"})

print(f"ä»»å‹™ï¼š{result.tasks}")
print(f"å„ªå…ˆç´šï¼š{result.priority}")
print(f"æˆªæ­¢æ™‚é–“ï¼š{result.deadline}")
print(f"é ä¼°å·¥æ™‚ï¼š{result.estimated_hours}")
```

### 2. JsonOutputParserï¼ˆè¼•é‡ç´šï¼‰

```python
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# å»ºç«‹ JSON è§£æå™¨
json_parser = JsonOutputParser()

# å»ºç«‹æç¤ºè©æ¨¡æ¿
prompt = PromptTemplate(
    template="åˆ†æä»¥ä¸‹å…§å®¹ä¸¦ä»¥ JSON æ ¼å¼è¿”å›ï¼š{text}\nè«‹åŒ…å«ï¼šsentiment, keywords, summary",
    input_variables=["text"]
)

# å»ºç«‹è™•ç†éˆ
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
chain = prompt | llm | json_parser

# åŸ·è¡Œåˆ†æ
result = chain.invoke({"text": "AIæŠ€è¡“ç™¼å±•è¿…é€Ÿï¼Œæœªä¾†å‰æ™¯çœ‹å¥½"})

# è™•ç†å­—å…¸çµæœ
print(result["sentiment"])  # "positive"
print(result["keywords"])   # ["AI", "æŠ€è¡“", "ç™¼å±•"]
print(result["summary"])    # "æ–‡ç« å°AIç™¼å±•æŒæ¨‚è§€æ…‹åº¦"
```

### 3. CommaSeparatedListOutputParserï¼ˆæ¸…å–®ï¼‰

```python
from langchain_core.output_parsers import CommaSeparatedListOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# å»ºç«‹é€—è™Ÿåˆ†éš”æ¸…å–®è§£æå™¨
list_parser = CommaSeparatedListOutputParser()

# å»ºç«‹æç¤ºè©æ¨¡æ¿
prompt = PromptTemplate(
    template="åˆ—å‡º {topic} çš„ä¸»è¦ç‰¹é»ï¼Œä»¥é€—è™Ÿåˆ†éš”ï¼š\n{format_instructions}",
    input_variables=["topic"],
    partial_variables={"format_instructions": list_parser.get_format_instructions()}
)

# å»ºç«‹è™•ç†éˆ
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
chain = prompt | llm | list_parser

# åŸ·è¡Œæ¸…å–®ç”Ÿæˆ
result = chain.invoke({"topic": "Python ç¨‹å¼èªè¨€"})
print(result)  # ['ç°¡å–®æ˜“å­¸', 'èªæ³•æ¸…æ™°', 'è±å¯Œçš„å‡½å¼åº«', 'è·¨å¹³å°', 'é–‹æº']
print(type(result))  # <class 'list'>
```

### 4. EnumOutputParserï¼ˆæšèˆ‰é™åˆ¶ï¼‰

```python
from langchain.output_parsers.enum import EnumOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from enum import Enum

# å®šç¾©å„ªå…ˆç´šæšèˆ‰
class Priority(Enum):
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"

# å»ºç«‹æšèˆ‰è§£æå™¨
enum_parser = EnumOutputParser(enum=Priority)

# å»ºç«‹æç¤ºè©æ¨¡æ¿
prompt = PromptTemplate(
    template="è©•ä¼°ä»¥ä¸‹ä»»å‹™çš„å„ªå…ˆç´šï¼š{task}\n{instructions}",
    input_variables=["task"],
    partial_variables={"instructions": enum_parser.get_format_instructions()}
)

# å»ºç«‹è™•ç†éˆ
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
chain = prompt | llm | enum_parser

# åŸ·è¡Œå„ªå…ˆç´šè©•ä¼°
result = chain.invoke({"task": "ä¿®å¾©ç”Ÿç”¢ç’°å¢ƒçš„ç·Šæ€¥ bug"})
print(result)        # Priority.HIGH
print(result.value)  # "high"
```

### 5. XMLOutputParserï¼ˆå®‰å…¨è§£æï¼‰

```python
from langchain_core.output_parsers import XMLOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# å»ºç«‹ XML è§£æå™¨ï¼ˆé è¨­ä½¿ç”¨ defusedxmlï¼Œè¼ƒå®‰å…¨ï¼‰
xml_parser = XMLOutputParser()

# å»ºç«‹æç¤ºè©æ¨¡æ¿
prompt = PromptTemplate(
    template="å°‡ä»¥ä¸‹è³‡è¨Šè½‰æ›ç‚º XML æ ¼å¼ï¼š{data}\n{format_instructions}",
    input_variables=["data"],
    partial_variables={"format_instructions": xml_parser.get_format_instructions()}
)

# å»ºç«‹è™•ç†éˆ
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
chain = prompt | llm | xml_parser

# åŸ·è¡Œ XML è½‰æ›
result = chain.invoke({"data": "åç¨±ï¼šå¼µä¸‰ï¼Œå¹´é½¡ï¼š30ï¼Œè·æ¥­ï¼šå·¥ç¨‹å¸«"})
print(result)  # è§£æå¾Œçš„ XML çµæ§‹
```

> **å®‰å…¨è¨»è¨˜**ï¼š`XMLOutputParser` é è¨­ä½¿ç”¨ `defusedxml` é€²è¡Œå®‰å…¨è§£æï¼Œå¯é˜²ç¯„ XML å¤–éƒ¨å¯¦é«”æ”»æ“Šï¼ˆXXEï¼‰ã€‚

---

## å¯é åº¦å¢å¼·ï¼šéŒ¯èª¤è™•ç†ç­–ç•¥

åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ï¼ŒLLM å¯èƒ½ç”¢ç”Ÿæ ¼å¼éŒ¯èª¤çš„è¼¸å‡ºã€‚ä»¥ä¸‹æ˜¯å¢å¼·å¯é åº¦çš„ç­–ç•¥ï¼š

### æ±ºç­–å»ºè­°ï¼ˆæ–°æ‰‹çœ‹å¾—æ‡‚ï¼‰

1. **èƒ½ç”¨ `with_structured_output` å°±å…ˆç”¨å®ƒ**ï¼ˆOpenAI/Anthropic/Google å¤šæ•¸æ”¯æ´ï¼‰
2. **å…¶ä»–æ¨¡å‹**â†’ç”¨ `JsonOutputParser` / `PydanticOutputParser`
3. **ä»æœƒé£„**â†’æœ€å¾Œå†ä¸Š `OutputFixingParser`

### 1. OutputFixingParserï¼ˆè£œæ•‘æ‰‹æ®µï¼‰

```python
from langchain.output_parsers import OutputFixingParser
from langchain_core.output_parsers import PydanticOutputParser
from langchain_openai import ChatOpenAI

# å»ºç«‹åŸå§‹è§£æå™¨
base_parser = PydanticOutputParser(pydantic_object=TaskExtraction)

# å»ºç«‹éŒ¯èª¤ä¿®å¾©è§£æå™¨ï¼ˆç•¶æ•‘ç«ç”¨ï¼‰
fixing_parser = OutputFixingParser.from_llm(
    parser=base_parser,
    llm=ChatOpenAI(model="gpt-4o-mini")
)

# ä½¿ç”¨ä¿®å¾©è§£æå™¨
chain = prompt | llm | fixing_parser
result = chain.invoke({"text": "å®Œæˆå ±å‘Šï¼Œå¾ˆé‡è¦"})  # å³ä½¿æ ¼å¼ä¸å®Œç¾ä¹Ÿèƒ½è§£æ
```

> **é‡è¦**ï¼š`OutputFixingParser` æ˜¯**è£œæ•‘æ‰‹æ®µ**ï¼Œä¸æ˜¯ä¸»ç·šæµç¨‹ã€‚å„ªå…ˆè€ƒæ…®æ”¹å–„æç¤ºè©å“è³ªã€‚

### 2. å¤šå±¤å®¹éŒ¯ç­–ç•¥

```python
from langchain_core.output_parsers import StrOutputParser
import logging

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)

class RobustParsingChain:
    """å…·å‚™å¤šå±¤å®¹éŒ¯çš„è§£æéˆ"""
    
    def __init__(self, primary_parser, fallback_parser=None):
        self.primary_parser = primary_parser  # ä¸»è¦è§£æå™¨
        self.fallback_parser = fallback_parser or StrOutputParser()  # å‚™ç”¨è§£æå™¨
    
    def parse_with_fallback(self, llm_output: str):
        """å¤šå±¤å®¹éŒ¯è§£æ"""
        try:
            # ç¬¬ä¸€å±¤ï¼šå˜—è©¦ä¸»è¦è§£æå™¨
            return self.primary_parser.parse(llm_output)
        except Exception as e:
            # ç¬¬äºŒå±¤ï¼šè¨˜éŒ„å¤±æ•—ä¸¦ä½¿ç”¨å‚™ç”¨è§£æå™¨
            logger.warning(f"ä¸»è§£æå™¨å¤±æ•—ï¼š{e}ï¼Œä½¿ç”¨å‚™ç”¨è§£æå™¨")
            return self.fallback_parser.parse(llm_output)

# ä½¿ç”¨ç¯„ä¾‹
robust_parser = RobustParsingChain(
    primary_parser=PydanticOutputParser(pydantic_object=TaskExtraction),
    fallback_parser=StrOutputParser()
)
```

### 3. æ‰¹æ¬¡è™•ç†çš„éŒ¯èª¤æ”¶é›†

```python
from langchain_openai import ChatOpenAI

# å»ºç«‹æ”¯æ´ä¾‹å¤–æ”¶é›†çš„æ‰¹æ¬¡è™•ç†
llm = ChatOpenAI(model="gpt-4o-mini", max_retries=3)
inputs = [{"text": "ä»»å‹™1"}, {"text": "ä»»å‹™2"}, {"text": "ä»»å‹™3"}]

# æ‰¹æ¬¡è™•ç†ä¸¦æ”¶é›†ä¾‹å¤–
results = chain.batch(inputs, config={"max_concurrency": 3}, return_exceptions=True)

# è™•ç†çµæœå’Œä¾‹å¤–
for i, result in enumerate(results):
    if isinstance(result, Exception):
        print(f"ç¬¬ {i+1} å€‹è«‹æ±‚å¤±æ•—ï¼š{result}")
    else:
        print(f"ç¬¬ {i+1} å€‹è«‹æ±‚æˆåŠŸï¼š{result}")
```

---

## æµç¨‹æ¯”è¼ƒåœ–

```mermaid
graph TD
    A[æ–‡å­—è¼¸å…¥] --> B{æ¨¡å‹æ”¯æ´ JSON æ¨¡å¼ï¼Ÿ}
    
    B -->|æ˜¯| C[with_structured_output]
    C --> D[âœ… æœ€ç©©å®šçµæœ]
    
    B -->|å¦| E[å‚³çµ± Output Parsers]
    E --> F[PydanticOutputParser]
    E --> G[JsonOutputParser]
    E --> H[å…¶ä»–å°ˆç”¨è§£æå™¨]
    
    F --> I{è§£ææˆåŠŸï¼Ÿ}
    G --> I
    H --> I
    
    I -->|å¦| J[OutputFixingParser]
    J --> K{ä¿®å¾©æˆåŠŸï¼Ÿ}
    
    K -->|å¦| L[å‚™ç”¨è§£æå™¨ StrOutputParser]
    K -->|æ˜¯| M[âœ… ä¿®å¾©å¾Œçµæœ]
    I -->|æ˜¯| M
    L --> N[âš ï¸ é™ç´šè™•ç†]
    
    style C fill:#90EE90
    style D fill:#90EE90
    style J fill:#FFE4B5
    style L fill:#FFB6C1
```

---

## æœ€ä½³å¯¦è¸å»ºè­°

### 1. é¸æ“‡ç­–ç•¥

- **é¦–é¸**ï¼šæ”¯æ´ JSON æ¨¡å¼çš„æ¨¡å‹ + `with_structured_output`
- **æ¬¡é¸**ï¼š`PydanticOutputParser`ï¼ˆé¡å‹å®‰å…¨ã€é©—è­‰å®Œæ•´ï¼‰
- **è¼•é‡**ï¼š`JsonOutputParser`ï¼ˆç°¡å–®å¿«é€Ÿï¼‰
- **ç‰¹æ®Šéœ€æ±‚**ï¼š`CommaSeparatedListOutputParser`ã€`EnumOutputParser` ç­‰

### 2. éŒ¯èª¤è™•ç†å±¤æ¬¡

1. **é‡è©¦æ©Ÿåˆ¶**ï¼šè¨­å®š `max_retries=3`
2. **ä¿®å¾©è§£æå™¨**ï¼š`OutputFixingParser`
3. **å‚™ç”¨è§£æå™¨**ï¼š`StrOutputParser`
4. **è¨˜éŒ„å¤±æ•—æ¡ˆä¾‹**ï¼šé¿å…éœé»˜åéŒ¯

### 3. æ•ˆèƒ½å„ªåŒ–

```python
from functools import lru_cache

# âŒ éŒ¯èª¤ï¼šlru_cache ç„¡æ³•å¿«å– self
class BadCachedParser(PydanticOutputParser):
    @lru_cache(maxsize=128)  # é€™æœƒå¤±æ•—ï¼
    def get_format_instructions(self):
        return super().get_format_instructions()

# âœ… æ­£ç¢ºï¼šæ¨¡çµ„å±¤ç´šå¿«å–
@lru_cache(maxsize=128)
def get_cached_format_instructions(pydantic_class):
    """æ¨¡çµ„å±¤ç´šçš„æ ¼å¼æŒ‡ç¤ºå¿«å–"""
    parser = PydanticOutputParser(pydantic_object=pydantic_class)
    return parser.get_format_instructions()

# ä½¿ç”¨å¿«å–
format_instructions = get_cached_format_instructions(TaskExtraction)
```

### 4. æç¤ºè©æœ€ä½³åŒ–

```python
# å¥½çš„æç¤ºè©ç¯„ä¾‹
good_prompt = """
è«‹åˆ†æä»¥ä¸‹æ–‡å­—ä¸¦ä»¥ JSON æ ¼å¼å›è¦†ï¼Œå¿…é ˆåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
- sentiment: "positive", "negative", æˆ– "neutral"
- confidence: 0 åˆ° 1 ä¹‹é–“çš„æ•¸å­—
- keywords: å­—ä¸²é™£åˆ—

ç¯„ä¾‹è¼¸å‡ºï¼š
{
  "sentiment": "positive", 
  "confidence": 0.85,
  "keywords": ["æŠ€è¡“", "å‰µæ–°", "ç™¼å±•"]
}

è¦åˆ†æçš„æ–‡å­—ï¼š{text}
"""
```

---

## å¸¸è¦‹éŒ¯èª¤èˆ‡è§£æ±ºæ–¹æ¡ˆ

### 1. åŒ¯å…¥è·¯å¾‘éŒ¯èª¤
```python
# âŒ éæ™‚è·¯å¾‘
from langchain_openai.chat_models import ChatOpenAI

# âœ… v0.3 æ­£ç¢ºè·¯å¾‘
from langchain_openai import ChatOpenAI
```

### 2. Pydantic ç‰ˆæœ¬æ··ç”¨
```python
# âŒ ä¸è¦æ··ç”¨ v1 å’Œ v2
from pydantic.v1 import BaseModel
from pydantic import validator

# âœ… çµ±ä¸€ä½¿ç”¨ v2
from pydantic import BaseModel, Field, field_validator
```

### 3. æœªå®šç¾©è®Šæ•¸
```python
# âŒ ç¼ºå°‘åŒ¯å…¥
chain = prompt | llm | parser  # PromptTemplate æœªåŒ¯å…¥

# âœ… å®Œæ•´åŒ¯å…¥
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import PydanticOutputParser
```

---

## ç¸½çµ

çµæ§‹åŒ–è¼¸å‡ºè§£æå™¨æ˜¯ LangChain ä¸­ç¢ºä¿è³‡æ–™å“è³ªå’Œé¡å‹å®‰å…¨çš„é—œéµçµ„ä»¶ï¼š

- ğŸ¯ **é¦–é¸ `with_structured_output`** - æœ€ç©©å®šã€æœ€ç°¡æ½”çš„æ–¹æ¡ˆ
- ğŸ›¡ï¸ **å‚™ç”¨ PydanticOutputParser** - å®Œæ•´çš„é¡å‹æª¢æŸ¥å’Œé©—è­‰
- ğŸ”„ **éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶** - OutputFixingParser å’Œå¤šå±¤å®¹éŒ¯
- âš¡ **æ•ˆèƒ½å„ªåŒ–** - å¿«å–æ ¼å¼æŒ‡ç¤ºã€æ‰¹æ¬¡è™•ç†
- ğŸ”§ **æ˜“æ–¼æ•´åˆ** - èˆ‡ LCEL ç„¡ç¸«çµåˆ

é¸æ“‡åˆé©çš„è§£æå™¨é¡å‹ï¼Œçµåˆè‰¯å¥½çš„éŒ¯èª¤è™•ç†ç­–ç•¥ï¼Œèƒ½å¤ å¤§å¤§æå‡ AI æ‡‰ç”¨çš„å¯é æ€§å’Œå¯ç¶­è­·æ€§ã€‚

---

::: tip ä¸‹ä¸€æ­¥
ç¾åœ¨ä½ å·²ç¶“æŒæ¡äº†çµæ§‹åŒ–è¼¸å‡ºè§£æï¼Œæ¥ä¸‹ä¾†å¯ä»¥ï¼š
1. [è¨˜æ†¶æ©Ÿåˆ¶èˆ‡å°è©±ç®¡ç†](/tutorials/memory-systems) - çµåˆçµæ§‹åŒ–è¼¸å‡ºå»ºæ§‹æ™ºèƒ½å°è©±
2. [ç›£æ§èˆ‡å¯è§€æ¸¬æ€§](/tutorials/monitoring) - ç›£æ§è§£æå™¨çš„æ€§èƒ½å’Œæº–ç¢ºæ€§
3. [é€²éšæ‡‰ç”¨æ¡ˆä¾‹](/tutorials/advanced-examples) - æŸ¥çœ‹ä¼æ¥­ç´šçš„è§£æå™¨æ‡‰ç”¨
:::

::: warning é–‹ç™¼å»ºè­°
- **å„ªå…ˆä½¿ç”¨ `with_structured_output`**ï¼šåœ¨æ”¯æ´çš„æ¨¡å‹ä¸Šé€™æ˜¯æœ€ä½³é¸æ“‡
- **è¬¹æ…è¨­è¨ˆ Schema**ï¼šæ¸…æ™°çš„æ¬„ä½æè¿°æœ‰åŠ©æ–¼æé«˜è§£ææº–ç¢ºæ€§
- **å……åˆ†æ¸¬è©¦**ï¼šç‚ºä¸åŒçš„è¼¸å…¥æƒ…æ³ç·¨å¯«æ¸¬è©¦ç”¨ä¾‹
- **éŒ¯èª¤è™•ç†**ï¼šå§‹çµ‚æº–å‚™å‚™ç”¨è§£æç­–ç•¥
- **æ•ˆèƒ½ç›£æ§**ï¼šè¿½è¹¤è§£ææˆåŠŸç‡å’ŒåŸ·è¡Œæ™‚é–“
:::