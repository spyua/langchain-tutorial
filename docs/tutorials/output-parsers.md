# çµæ§‹åŒ–è¼¸å‡ºè§£æå™¨ (Output Parsers)

## ç‚ºä»€éº¼éœ€è¦çµæ§‹åŒ–è¼¸å‡ºï¼Ÿ

LLM çš„åŸå§‹è¼¸å‡ºé€šå¸¸æ˜¯éçµæ§‹åŒ–çš„æ–‡å­—ï¼Œä½†å¯¦éš›æ‡‰ç”¨ä¸­æˆ‘å€‘ç¶“å¸¸éœ€è¦çµæ§‹åŒ–è³‡æ–™ä¾†é€²è¡Œå¾ŒçºŒè™•ç†ã€‚

### å•é¡Œå ´æ™¯
```python
# âŒ åŸå§‹ LLM è¼¸å‡ºï¼šé›£ä»¥ç¨‹å¼åŒ–è™•ç†
response = llm.invoke("åˆ†æé€™ç¯‡æ–‡ç« çš„æƒ…æ„Ÿ")
print(response.content)  # "é€™ç¯‡æ–‡ç« æ•´é«”æƒ…æ„Ÿåå‘æ­£é¢ï¼Œä¿¡å¿ƒæŒ‡æ•¸ç´„ 85%ï¼Œä¸»è¦æƒ…æ„Ÿé¡åˆ¥æ˜¯æ¨‚è§€..."

# ğŸ˜¤ éœ€è¦æ‰‹å‹•è§£æå­—ä¸²ï¼Œå®¹æ˜“å‡ºéŒ¯
if "æ­£é¢" in response.content:
    sentiment = "positive"
else:
    sentiment = "negative"
```

### è§£æ±ºæ–¹æ¡ˆï¼šçµæ§‹åŒ–è¼¸å‡º
```python
# âœ… ä½¿ç”¨ Output Parserï¼šç²å¾—çµæ§‹åŒ–è³‡æ–™
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

class SentimentAnalysis(BaseModel):
    sentiment: str = Field(description="æƒ…æ„Ÿå‚¾å‘ï¼špositive, negative, neutral")
    confidence: float = Field(description="ä¿¡å¿ƒæŒ‡æ•¸ 0-1", ge=0, le=1)
    emotions: list[str] = Field(description="æª¢æ¸¬åˆ°çš„æƒ…æ„Ÿæ¸…å–®")
    summary: str = Field(description="åˆ†æç¸½çµ")

parser = PydanticOutputParser(pydantic_object=SentimentAnalysis)
chain = prompt | llm | parser

result = chain.invoke({"text": "ä»Šå¤©å¤©æ°£çœŸå¥½ï¼"})
print(result)  # SentimentAnalysis ç‰©ä»¶
print(result.sentiment)     # "positive"
print(result.confidence)    # 0.95
print(result.emotions)      # ["happiness", "optimism"]
```

## Output Parser é¡å‹ç¸½è¦½

### 1. Pydantic Output Parser
**æœ€æ¨è–¦çš„çµæ§‹åŒ–è¼¸å‡ºæ–¹å¼**

```python
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field, validator
from typing import List, Optional
from datetime import datetime

class TaskExtraction(BaseModel):
    """ä»»å‹™æå–çµæœ"""
    tasks: List[str] = Field(description="æå–çš„ä»»å‹™æ¸…å–®")
    priority: str = Field(description="å„ªå…ˆç´šï¼šhigh, medium, low")
    deadline: Optional[str] = Field(description="æˆªæ­¢æ™‚é–“ï¼Œæ ¼å¼ï¼šYYYY-MM-DD")
    estimated_hours: float = Field(description="é ä¼°å·¥æ™‚", ge=0)
    
    @validator('priority')
    def validate_priority(cls, v):
        if v not in ['high', 'medium', 'low']:
            raise ValueError('å„ªå…ˆç´šå¿…é ˆæ˜¯ high, medium, low å…¶ä¸­ä¹‹ä¸€')
        return v

# ä½¿ç”¨ç¯„ä¾‹
parser = PydanticOutputParser(pydantic_object=TaskExtraction)
prompt = PromptTemplate(
    template="å¾ä»¥ä¸‹æ–‡æœ¬æå–ä»»å‹™è³‡è¨Šï¼š{text}\n{format_instructions}",
    input_variables=["text"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)

chain = prompt | llm | parser
result = chain.invoke({"text": "éœ€è¦åœ¨æœ¬é€±äº”å‰å®Œæˆç¶²ç«™è¨­è¨ˆï¼Œé ä¼°éœ€è¦ 8 å°æ™‚ï¼Œé€™æ˜¯é«˜å„ªå…ˆç´šä»»å‹™"})
print(f"ä»»å‹™ï¼š{result.tasks}")
print(f"å„ªå…ˆç´šï¼š{result.priority}")
print(f"æˆªæ­¢æ™‚é–“ï¼š{result.deadline}")
```

### 2. JSON Output Parser
**è¼•é‡ç´š JSON çµæ§‹è¼¸å‡º**

```python
from langchain_core.output_parsers import JsonOutputParser

json_parser = JsonOutputParser()
prompt = PromptTemplate(
    template="åˆ†æä»¥ä¸‹å…§å®¹ä¸¦ä»¥ JSON æ ¼å¼è¿”å›ï¼š{text}\nè«‹åŒ…å«ï¼šsentiment, keywords, summary",
    input_variables=["text"]
)

chain = prompt | llm | json_parser
result = chain.invoke({"text": "AIæŠ€è¡“ç™¼å±•è¿…é€Ÿï¼Œæœªä¾†å‰æ™¯çœ‹å¥½"})
# result æ˜¯dict æ ¼å¼
print(result["sentiment"])  # "positive"
print(result["keywords"])   # ["AI", "æŠ€è¡“", "ç™¼å±•"]
```

### 3. Structured Output Parser
**åŸºæ–¼ Response Schema çš„çµæ§‹åŒ–è¼¸å‡º**

```python
from langchain.output_parsers import StructuredOutputParser, ResponseSchema

response_schemas = [
    ResponseSchema(name="product_name", description="ç”¢å“åç¨±"),
    ResponseSchema(name="price", description="åƒ¹æ ¼ï¼ˆæ•¸å­—ï¼‰"),
    ResponseSchema(name="features", description="ä¸»è¦ç‰¹è‰²æ¸…å–®"),
    ResponseSchema(name="recommendation", description="æ˜¯å¦æ¨è–¦ï¼ˆtrue/falseï¼‰")
]

parser = StructuredOutputParser.from_response_schemas(response_schemas)
format_instructions = parser.get_format_instructions()

prompt = PromptTemplate(
    template="åˆ†æä»¥ä¸‹ç”¢å“è³‡è¨Šï¼š{product_info}\n{format_instructions}",
    input_variables=["product_info"],
    partial_variables={"format_instructions": format_instructions}
)

chain = prompt | llm | parser
result = chain.invoke({"product_info": "iPhone 15 Proï¼Œå”®åƒ¹ NT$35,900ï¼Œå…·å‚™ A17 Pro æ™¶ç‰‡å’Œéˆ¦é‡‘å±¬æ©Ÿèº«"})
print(result)  # çµæ§‹åŒ–å­—å…¸è¼¸å‡º
```

### 4. Enum Output Parser
**æšèˆ‰é¡å‹è¼¸å‡º**

```python
from langchain_core.output_parsers import EnumOutputParser
from enum import Enum

class Priority(Enum):
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"

parser = EnumOutputParser(enum=Priority)
prompt = PromptTemplate(
    template="è©•ä¼°ä»¥ä¸‹ä»»å‹™çš„å„ªå…ˆç´šï¼š{task}\n{instructions}",
    input_variables=["task"],
    partial_variables={"instructions": parser.get_format_instructions()}
)

chain = prompt | llm | parser
result = chain.invoke({"task": "ä¿®å¾©ç”Ÿç”¢ç’°å¢ƒçš„ç·Šæ€¥ bug"})
print(result)  # Priority.HIGH
print(result.value)  # "high"
```

## é€²éšè¼¸å‡ºè§£ææŠ€è¡“

### 1. è‡ªå®šç¾©è¼¸å‡ºè§£æå™¨

```python
from langchain_core.output_parsers import BaseOutputParser
from typing import List
import re

class EmailExtractorParser(BaseOutputParser[List[str]]):
    """è‡ªå®šç¾©éƒµä»¶åœ°å€æå–å™¨"""
    
    def parse(self, text: str) -> List[str]:
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–éƒµä»¶åœ°å€
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        emails = re.findall(email_pattern, text)
        return list(set(emails))  # å»é‡
    
    @property
    def _type(self) -> str:
        return "email_extractor"

# ä½¿ç”¨è‡ªå®šç¾©è§£æå™¨
parser = EmailExtractorParser()
chain = prompt | llm | parser
emails = chain.invoke({"text": "è«‹è¯çµ¡ john@example.com æˆ– mary@company.org"})
print(emails)  # ['john@example.com', 'mary@company.org']
```

### 2. éŒ¯èª¤è™•ç†èˆ‡é‡è©¦æ©Ÿåˆ¶

```python
from langchain_core.output_parsers import OutputFixingParser
from langchain_core.output_parsers import PydanticOutputParser

# åŸå§‹è§£æå™¨
base_parser = PydanticOutputParser(pydantic_object=TaskExtraction)

# åŒ…è£éŒ¯èª¤ä¿®å¾©è§£æå™¨
fixing_parser = OutputFixingParser.from_llm(
    parser=base_parser,
    llm=ChatOpenAI(model="gpt-4o-mini")
)

# ç•¶åŸå§‹è§£æå¤±æ•—æ™‚ï¼Œæœƒä½¿ç”¨ LLM ä¿®å¾©è¼¸å‡ºæ ¼å¼
chain = prompt | llm | fixing_parser
result = chain.invoke({"text": "å®Œæˆå ±å‘Šï¼Œå¾ˆé‡è¦"})  # å³ä½¿è¼¸å‡ºæ ¼å¼ä¸å®Œç¾ä¹Ÿèƒ½è§£æ
```

### 3. å¤šæ­¥é©Ÿè§£æç®¡é“

```python
# è¤‡é›œçš„å¤šæ­¥é©Ÿè§£ææµç¨‹
from langchain_core.runnables import RunnablePassthrough

# ç¬¬ä¸€æ­¥ï¼šåŸºæœ¬è³‡è¨Šæå–
basic_parser = PydanticOutputParser(pydantic_object=BasicInfo)

# ç¬¬äºŒæ­¥ï¼šè©³ç´°åˆ†æ
detailed_parser = PydanticOutputParser(pydantic_object=DetailedAnalysis)

# çµ„åˆè§£æç®¡é“
analysis_chain = {
    "basic": basic_prompt | llm | basic_parser,
    "original": RunnablePassthrough()
} | detailed_prompt | llm | detailed_parser

result = analysis_chain.invoke({"input_text": "åˆ†æå°è±¡"})
```

## æœ€ä½³å¯¦è¸å»ºè­°

### 1. é¸æ“‡åˆé©çš„è§£æå™¨

| ä½¿ç”¨å ´æ™¯ | æ¨è–¦è§£æå™¨ | å„ªå‹¢ |
|----------|------------|------|
| **è¤‡é›œæ¥­å‹™é‚è¼¯** | PydanticOutputParser | é¡å‹å®‰å…¨ã€é©—è­‰å®Œæ•´ã€IDE æ”¯æ´ |
| **ç°¡å–® JSON è¼¸å‡º** | JsonOutputParser | è¼•é‡ç´šã€å¿«é€Ÿ |
| **å›ºå®šæ¬„ä½çµæ§‹** | StructuredOutputParser | é…ç½®ç°¡å–®ã€å‘å¾Œç›¸å®¹ |
| **æšèˆ‰é¸æ“‡** | EnumOutputParser | é¡å‹å®‰å…¨ã€é¸é …é™åˆ¶ |
| **ç‰¹æ®Šæ ¼å¼** | è‡ªå®šç¾© Parser | å®Œå…¨å®¢è£½åŒ– |

### 2. éŒ¯èª¤è™•ç†ç­–ç•¥

```python
# ğŸ”’ å …å›ºçš„éŒ¯èª¤è™•ç†
class RobustParsingChain:
    def __init__(self, primary_parser, fallback_parser=None):
        self.primary_parser = primary_parser
        self.fallback_parser = fallback_parser or StrOutputParser()
    
    def parse_with_fallback(self, llm_output):
        try:
            return self.primary_parser.parse(llm_output)
        except Exception as e:
            logger.warning(f"ä¸»è§£æå™¨å¤±æ•—ï¼š{e}ï¼Œä½¿ç”¨å‚™ç”¨è§£æå™¨")
            return self.fallback_parser.parse(llm_output)

# ä½¿ç”¨ç¯„ä¾‹
robust_parser = RobustParsingChain(
    primary_parser=PydanticOutputParser(pydantic_object=MyModel),
    fallback_parser=StrOutputParser()
)
```

### 3. æ€§èƒ½å„ªåŒ–

```python
# ğŸš€ å¿«å–è§£ææŒ‡ç¤º
from functools import lru_cache

class CachedParser(PydanticOutputParser):
    @lru_cache(maxsize=128)
    def get_format_instructions(self):
        return super().get_format_instructions()

# æ‰¹é‡è§£æå„ªåŒ–
def batch_parse(texts: List[str], parser):
    """æ‰¹é‡è§£æï¼Œæé«˜æ•ˆç‡"""
    chain = prompt | llm | parser
    return chain.batch([{"text": text} for text in texts])
```

### 4. èˆ‡ LCEL æ•´åˆ

```python
# åœ¨ LCEL éˆä¸­ä½¿ç”¨çµæ§‹åŒ–è¼¸å‡º
from langchain_core.runnables import RunnableParallel

# ä¸¦è¡Œè§£æå¤šç¨®æ ¼å¼
multi_format_chain = RunnableParallel({
    "structured": prompt | llm | pydantic_parser,
    "json": prompt | llm | json_parser,
    "enum": priority_prompt | llm | enum_parser
})

results = multi_format_chain.invoke({"text": "è¼¸å…¥æ–‡æœ¬"})
```

## å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹

### æ™ºèƒ½è¡¨å–®å¡«å¯«ç³»çµ±

```python
class FormData(BaseModel):
    name: str = Field(description="å§“å")
    email: str = Field(description="éƒµä»¶åœ°å€")
    phone: Optional[str] = Field(description="é›»è©±è™Ÿç¢¼")
    age: int = Field(description="å¹´é½¡", ge=0, le=150)
    interests: List[str] = Field(description="èˆˆè¶£æ„›å¥½")
    
form_parser = PydanticOutputParser(pydantic_object=FormData)
form_prompt = PromptTemplate(
    template="å¾ä»¥ä¸‹å°è©±ä¸­æå–è¡¨å–®è³‡è¨Šï¼š{conversation}\n{format_instructions}",
    input_variables=["conversation"],
    partial_variables={"format_instructions": form_parser.get_format_instructions()}
)

form_chain = form_prompt | llm | form_parser

conversation = """
ç”¨æˆ¶: ä½ å¥½ï¼Œæˆ‘å«å¼µå°æ˜ï¼Œä»Šå¹´28æ­²
å®¢æœ: æ‚¨å¥½ï¼è«‹å•æ‚¨çš„è¯çµ¡æ–¹å¼ï¼Ÿ
ç”¨æˆ¶: æˆ‘çš„éƒµç®±æ˜¯zhangxm@email.comï¼Œæ‰‹æ©Ÿæ˜¯0912345678
å®¢æœ: æ‚¨æœ‰ä»€éº¼èˆˆè¶£æ„›å¥½å—ï¼Ÿ
ç”¨æˆ¶: æˆ‘å–œæ­¡æ”å½±ã€æ—…éŠå’Œé–±è®€
"""

form_data = form_chain.invoke({"conversation": conversation})
print(f"å§“å: {form_data.name}")
print(f"å¹´é½¡: {form_data.age}")
print(f"éƒµç®±: {form_data.email}")
print(f"èˆˆè¶£: {', '.join(form_data.interests)}")
```

### æ™ºèƒ½åˆç´„æ¢æ¬¾è§£æ

```python
class ContractClause(BaseModel):
    clause_type: str = Field(description="æ¢æ¬¾é¡å‹ï¼špayment, delivery, warranty, penalty")
    description: str = Field(description="æ¢æ¬¾æè¿°")
    key_terms: List[str] = Field(description="é—œéµæ¢ä»¶")
    risk_level: str = Field(description="é¢¨éšªç­‰ç´šï¼šlow, medium, high")

contract_parser = PydanticOutputParser(pydantic_object=ContractClause)
contract_chain = contract_prompt | legal_llm | contract_parser

contract_text = """
ç¬¬äº”æ¢ ä»˜æ¬¾æ¢æ¬¾ï¼šè²·æ–¹æ‡‰åœ¨æ”¶åˆ°è²¨ç‰©å¾Œ30å¤©å…§ä»˜æ¸…å…¨æ¬¾ï¼Œé€¾æœŸæ¯æ—¥æŒ‰æ¬ æ¬¾é‡‘é¡çš„0.05%è¨ˆæ”¶æ»¯ç´é‡‘ã€‚
å¦‚è¶…é60å¤©æœªä»˜æ¬¾ï¼Œè³£æ–¹æœ‰æ¬Šæ”¶å›è²¨ç‰©ä¸¦è¿½ç©¶é•ç´„è²¬ä»»ã€‚
"""

clause = contract_chain.invoke({"text": contract_text})
print(f"æ¢æ¬¾é¡å‹: {clause.clause_type}")
print(f"é¢¨éšªç­‰ç´š: {clause.risk_level}")
print(f"é—œéµæ¢ä»¶: {clause.key_terms}")
```

## ç¸½çµ

çµæ§‹åŒ–è¼¸å‡ºè§£æå™¨æ˜¯ LangChain ä¸­ç¢ºä¿è³‡æ–™å“è³ªå’Œé¡å‹å®‰å…¨çš„é—œéµçµ„ä»¶ï¼š

- ğŸ¯ **ç²¾ç¢ºæ§åˆ¶** - å®šç¾©æ˜ç¢ºçš„è¼¸å‡ºæ ¼å¼å’Œé©—è­‰è¦å‰‡
- ğŸ›¡ï¸ **é¡å‹å®‰å…¨** - Pydantic æ¨¡å‹æä¾›å®Œæ•´çš„é¡å‹æª¢æŸ¥
- ğŸ”„ **éŒ¯èª¤æ¢å¾©** - å…§å»ºé‡è©¦å’Œä¿®å¾©æ©Ÿåˆ¶
- âš¡ **é«˜æ•ˆè™•ç†** - æ”¯æ´æ‰¹é‡å’Œç•°æ­¥è™•ç†
- ğŸ”§ **æ˜“æ–¼æ•´åˆ** - èˆ‡ LCEL ç„¡ç¸«çµåˆ
- ğŸ“Š **å¤šæ ¼å¼æ”¯æ´** - JSONã€æšèˆ‰ã€è‡ªå®šç¾©æ ¼å¼

é¸æ“‡åˆé©çš„è§£æå™¨é¡å‹ï¼Œçµåˆè‰¯å¥½çš„éŒ¯èª¤è™•ç†ç­–ç•¥ï¼Œèƒ½å¤ å¤§å¤§æå‡ AI æ‡‰ç”¨çš„å¯é æ€§å’Œå¯ç¶­è­·æ€§ã€‚

---

::: tip ä¸‹ä¸€æ­¥
ç¾åœ¨ä½ å·²ç¶“æŒæ¡äº†çµæ§‹åŒ–è¼¸å‡ºè§£æï¼Œæ¥ä¸‹ä¾†å¯ä»¥ï¼š
1. [è¨˜æ†¶æ©Ÿåˆ¶èˆ‡å°è©±ç®¡ç†](/tutorials/memory-systems) - çµåˆçµæ§‹åŒ–è¼¸å‡ºå»ºæ§‹æ™ºèƒ½å°è©±
2. [ç›£æ§èˆ‡å¯è§€æ¸¬æ€§](/tutorials/monitoring) - ç›£æ§è§£æå™¨çš„æ€§èƒ½å’Œæº–ç¢ºæ€§
3. [é€²éšæ‡‰ç”¨æ¡ˆä¾‹](/tutorials/advanced-examples) - æŸ¥çœ‹ä¼æ¥­ç´šçš„è§£æå™¨æ‡‰ç”¨
:::

::: warning é–‹ç™¼å»ºè­°
- **è¬¹æ…è¨­è¨ˆ Schema**ï¼šæ¸…æ™°çš„æ¬„ä½æè¿°æœ‰åŠ©æ–¼æé«˜è§£ææº–ç¢ºæ€§
- **å……åˆ†æ¸¬è©¦**ï¼šç‚ºä¸åŒçš„è¼¸å…¥æƒ…æ³ç·¨å¯«æ¸¬è©¦ç”¨ä¾‹
- **éŒ¯èª¤è™•ç†**ï¼šå§‹çµ‚æº–å‚™å‚™ç”¨è§£æç­–ç•¥
- **æ€§èƒ½ç›£æ§**ï¼šè¿½è¹¤è§£ææˆåŠŸç‡å’ŒåŸ·è¡Œæ™‚é–“
:::