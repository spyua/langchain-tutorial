# Gemini åŸºç¤èŠå¤© Demo

é€™æ˜¯ä¸€å€‹ä½¿ç”¨ LangChain æ•´åˆ Google Gemini API çš„å®Œæ•´èŠå¤©æ‡‰ç”¨ç¨‹å¼ã€‚

## ğŸ“‹ Demo æ¦‚è¿°

### åŠŸèƒ½ç‰¹è‰²
- **API é€£æ¥æ¸¬è©¦** - é©—è­‰ Google API Key æœ‰æ•ˆæ€§
- **å¤šæ¨¡å‹æ”¯æ´** - æ”¯æ´ gemini-1.5-flashã€gemini-1.5-proã€gemini-1.0-pro
- **äº’å‹•å¼èŠå¤©** - å®Œæ•´çš„å°è©±ä»‹é¢
- **ç³»çµ±è³‡è¨Šé¡¯ç¤º** - ç’°å¢ƒè®Šæ•¸å’Œç‰ˆæœ¬è³‡è¨Š
- **éŒ¯èª¤è™•ç†** - å®Œå–„çš„ç•°å¸¸è™•ç†æ©Ÿåˆ¶

### æŠ€è¡“æ¶æ§‹
```mermaid
graph TB
    A[Streamlit UI] --> B[ç’°å¢ƒè®Šæ•¸æª¢æŸ¥]
    B --> C[API Key é©—è­‰]
    C --> D[LangChain åˆå§‹åŒ–]
    D --> E[ChatGoogleGenerativeAI]
    E --> F[Gemini API]
    F --> G[å›æ‡‰è™•ç†]
    G --> H[çµæœé¡¯ç¤º]
```

## ğŸ”§ æŠ€è¡“å¯¦ä½œ

### æ ¸å¿ƒä»£ç¢¼è§£æ

#### 1. ç’°å¢ƒè¨­ç½®èˆ‡æª¢æŸ¥
```python
from dotenv import load_dotenv
import os

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# æª¢æŸ¥ API Key
api_key = os.getenv("GOOGLE_API_KEY")
if api_key:
    st.success(f"âœ… æ‰¾åˆ°API Key (å‰8å­—å…ƒ: {api_key[:8]}...)")
else:
    st.error("âŒ æœªæ‰¾åˆ°GOOGLE_API_KEYç’°å¢ƒè®Šæ•¸")
```

#### 2. LangChain æ¨¡å‹åˆå§‹åŒ–
```python
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import HumanMessage, SystemMessage

# åˆå§‹åŒ–æ¨¡å‹
llm = ChatGoogleGenerativeAI(
    model=model_choice,
    google_api_key=api_key_input,
    temperature=0.7
)
```

#### 3. è¨Šæ¯è™•ç†
```python
# æ§‹å»ºè¨Šæ¯éˆ
messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€å€‹æœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡è©³ç´°å›ç­”å•é¡Œã€‚"),
    HumanMessage(content=user_question)
]

# ç™¼é€è«‹æ±‚ä¸¦ç²å–å›æ‡‰
response = llm.invoke(messages)
```

### é—œéµè¨­è¨ˆæ¨¡å¼

#### å‹•æ…‹å°å…¥
```python
# é¿å…å•Ÿå‹•æ™‚çš„å°å…¥éŒ¯èª¤
try:
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain.schema import HumanMessage, SystemMessage
except ImportError as e:
    st.error(f"å°å…¥éŒ¯èª¤: {e}")
```

#### éŒ¯èª¤è™•ç†
```python
try:
    response = llm.invoke(messages)
    st.success("âœ… é€£æ¥æˆåŠŸï¼")
    st.write(f"**Geminiå›æ‡‰:** {response.content}")
except Exception as e:
    st.error(f"âŒ é€£æ¥å¤±æ•—: {str(e)}")
```

## ğŸ¯ å­¸ç¿’é‡é»

### 1. LangChain åŸºç¤æ¦‚å¿µ
- **Language Models** - å¦‚ä½•åˆå§‹åŒ–å’Œé…ç½®æ¨¡å‹
- **Message Types** - SystemMessage å’Œ HumanMessage çš„ä½¿ç”¨
- **Model Invoke** - åŒæ­¥èª¿ç”¨æ¨¡å‹çš„æ–¹æ³•

### 2. Google Gemini æ•´åˆ
- **API Key ç®¡ç†** - å®‰å…¨çš„é‡‘é‘°è™•ç†æ–¹å¼
- **æ¨¡å‹é¸æ“‡** - ä¸åŒ Gemini æ¨¡å‹çš„ç‰¹é»
- **åƒæ•¸é…ç½®** - temperature ç­‰åƒæ•¸çš„å½±éŸ¿

### 3. Streamlit æ‡‰ç”¨é–‹ç™¼
- **é é¢é…ç½®** - set_page_config çš„ä½¿ç”¨
- **ç”¨æˆ¶ä»‹é¢** - è¡¨å–®å…ƒä»¶å’Œäº’å‹•è¨­è¨ˆ
- **ç‹€æ…‹ç®¡ç†** - æœƒè©±ç‹€æ…‹çš„è™•ç†

### 4. éŒ¯èª¤è™•ç†æœ€ä½³å¯¦è¸
- **å„ªé›…é™ç´š** - æ¨¡çµ„å°å…¥å¤±æ•—çš„è™•ç†
- **ç”¨æˆ¶å‹å¥½** - æ¸…æ¥šçš„éŒ¯èª¤è¨Šæ¯é¡¯ç¤º
- **åµéŒ¯è³‡è¨Š** - ç³»çµ±è³‡è¨Šçš„è¼”åŠ©é¡¯ç¤º

## ğŸš€ åŸ·è¡ŒæŒ‡å—

### æ­¥é©Ÿ 1: ç’°å¢ƒæº–å‚™
```bash
# ç¢ºä¿åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„
cd /path/to/gemini-langchain-test

# å®‰è£ä¾è³´
pip install -r requirements.txt
```

### æ­¥é©Ÿ 2: é…ç½® API Key
```bash
# å‰µå»º .env æª”æ¡ˆ
echo "GOOGLE_API_KEY=your_actual_api_key" > .env
```

### æ­¥é©Ÿ 3: åŸ·è¡Œ Demo
```bash
# é€²å…¥ Demo ç›®éŒ„
cd streamlit-demos/01_gemini_basic

# å•Ÿå‹•æ‡‰ç”¨
streamlit run gemini_chat.py
```

### æ­¥é©Ÿ 4: æ¸¬è©¦åŠŸèƒ½
1. é–‹å•Ÿç€è¦½å™¨åˆ° `http://localhost:8501`
2. æª¢æŸ¥ç³»çµ±è³‡è¨Šç¢ºèªç’°å¢ƒæ­£å¸¸
3. é»æ“Šã€Œæ¸¬è©¦é€£æ¥ã€é©—è­‰ API
4. åœ¨å°è©±å€åŸŸè¼¸å…¥å•é¡Œé€²è¡Œæ¸¬è©¦

## ğŸ“Š Demo æˆªåœ–

### ä¸»ä»‹é¢
- ç³»çµ±è³‡è¨Šå±•é–‹å€å¡Š
- API è¨­ç½®å€åŸŸ
- æ¨¡å‹é¸æ“‡ä¸‹æ‹‰é¸å–®
- é€£æ¥æ¸¬è©¦æŒ‰éˆ•

### å°è©±å€åŸŸ
- å•é¡Œè¼¸å…¥æ–‡å­—æ¡†
- ç™¼é€æŒ‰éˆ•
- å›æ‡‰é¡¯ç¤ºå€åŸŸ
- çµ±è¨ˆè³‡è¨Šå±•ç¤º

## ğŸ” é€²éšæ“´å±•

### 1. æ·»åŠ è¨˜æ†¶åŠŸèƒ½
```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
# æ•´åˆåˆ°å°è©±éˆä¸­
```

### 2. è‡ªå®šç¾©ç³»çµ±æç¤º
```python
system_prompts = {
    "åŠ©æ‰‹": "ä½ æ˜¯ä¸€å€‹æœ‰ç”¨çš„AIåŠ©æ‰‹...",
    "ç¿»è­¯": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­ç¿»è­¯...",
    "ç¨‹å¼": "ä½ æ˜¯ä¸€å€‹ç¨‹å¼è¨­è¨ˆå°ˆå®¶..."
}
```

### 3. å¤šè¼ªå°è©±æ”¯æ´
```python
if 'conversation' not in st.session_state:
    st.session_state.conversation = []

# ä¿å­˜å°è©±æ­·å²
st.session_state.conversation.append({
    "user": user_question,
    "assistant": response.content
})
```

## ğŸ› é™¤éŒ¯æŠ€å·§

### å¸¸è¦‹å•é¡Œè¨ºæ–·
1. **æª¢æŸ¥ç¶²è·¯é€£ç·š**
2. **é©—è­‰ API Key æ ¼å¼**
3. **ç¢ºèªæ¨¡å‹å¯ç”¨æ€§**
4. **æŸ¥çœ‹è©³ç´°éŒ¯èª¤è¨Šæ¯**

### æ—¥èªŒè¨˜éŒ„
```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_choice}")
logger.info(f"API Key é•·åº¦: {len(api_key)}")
```

---

::: tip æç¤º
é€™å€‹ Demo æ˜¯å­¸ç¿’ LangChain çš„çµ•ä½³èµ·é»ï¼Œå»ºè­°èŠ±æ™‚é–“ç†è§£æ¯å€‹å…ƒä»¶çš„ä½œç”¨ï¼Œä¸¦å˜—è©¦ä¿®æ”¹åƒæ•¸è§€å¯Ÿè®ŠåŒ–ã€‚
:::